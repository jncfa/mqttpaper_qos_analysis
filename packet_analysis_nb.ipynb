{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "'''MQTT Packet analysis script developed for the experiments ran in ISR.\n",
    "\n",
    "This script automatically performs the RTT and Packet Loss analysis of the packets given the folder containing\n",
    "all Wireshark capture files ('.pcap'). \n",
    "\n",
    "It uses pyshark (Python wrapper for the tshark tool) to analyze the packets.\n",
    "\n",
    "Setting up:\n",
    "    Use the supplied Dockerfile to setup a development environment, or manually install all dependencies.\n",
    "    Make sure to mount the folder with the log files in /logs/.\n",
    "'''\n",
    "import pyshark\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "# fix nested loop shenanigans with Jupyter & pyshark\n",
    "try:\n",
    "    shell = get_ipython().__class__.__name__\n",
    "    if shell == 'ZMQInteractiveShell':\n",
    "        import nest_asyncio\n",
    "        nest_asyncio.apply()\n",
    "    else: # Terminal running IPython or another type\n",
    "        pass\n",
    "except NameError:\n",
    "    pass      # Probably standard Python interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all experiment variables\n",
    "client_list =  ['10.231.219.206', '10.231.219.81', '10.231.219.73', '10.231.219.185']\n",
    "host_ip = '10.231.201.175'\n",
    "\n",
    "frequency_list =  [1, 10, 100]\n",
    "packet_sizes =  ['small', 'medium', 'large']\n",
    "qos_levels = [0, 1, 2]\n",
    "\n",
    "# Mapping to get real packet size\n",
    "packet_sizes_bytes = {'small': 1250, 'medium': 12500, 'large': 125000}\n",
    "\n",
    "# Headers to be used in pandas.DataFrame\n",
    "FREQUENCY_HEADER = 'FREQUENCY'\n",
    "PACKET_SIZE_HEADER = 'PACKET_SIZE'\n",
    "NUM_CLIENTS_HEADER = 'NUM_CLIENTS'\n",
    "QOS_LEVEL_HEADER = 'QOS_LEVEL'\n",
    "\n",
    "RTT_HEADER = 'RTT'\n",
    "RTT_MEAN_HEADER = 'RTT_MEAN' \n",
    "RTT_STD_HEADER = 'RTT_STD'\n",
    "PACKET_LOSS_HEADER = 'PACKET_LOSS'\n",
    "\n",
    "# Headers to be used in packet_raw_info\n",
    "TCP_SEGMENTS_HEADER = \"tcp.segment\" # segments that composed the packet\n",
    "TCP_FIRST_SEGMENT_HEADER = TCP_SEGMENTS_HEADER # first segment that composed the packet \n",
    "TCP_FIRST_SEGMENT_TIMESTAMP_HEADER = \"tcp.segments.timestamp\" # first segment that composed the packet \n",
    "\n",
    "MQTT_MSGID_HEADER = \"mqtt.msgid\" # id of the MQTT message, used to follow up on QoS on MQTT level\n",
    "MQTT_MSGLEN_HEADER = \"mqtt.msglen\" # full length of the packet (payload + overhead)\n",
    "FRAME_NUMBER_HEADER = \"frame.number\" # number of the frame\n",
    "FRAME_TIMESTAMP_HEADER = \"frame.time\" # timestamp of the recorded packet\n",
    "IP_ADDR_HEADER = \"ip.addr\"\n",
    "\n",
    "MQTT_PACKET_ACKED_HEADER = \"MQTT_PACKET_ACKED\" # indicates if the packed was acked or not\n",
    "MQTT_PACKET_ACK_TIMESTAMP_HEADER = \"MQTT_PACKET_ACK_TIMESTAMP\" # timestamp of packet ack (PUBACK for QoS1, PUBCOMP for QoS2)\n",
    "\n",
    "# Useful functions\n",
    "# Packet file name format\n",
    "filename_fmt = '/logs/f{}c{}qos{}{}.pcap'\n",
    "getLogFilename = lambda frequency, number_of_clients, qos_level, packet_size : filename_fmt.format(frequency, number_of_clients, qos_level, packet_size)\n",
    "\n",
    "# Get Client IP from ip.addr info\n",
    "getClientIP = lambda addr: addr[0] if addr[0] != host_ip else addr[1] \n",
    "\n",
    "# Create double FileCapture from capture file and display filter \n",
    "def createFileCapture(capture_filename, display_filter):\n",
    "    return pyshark.FileCapture(capture_filename, use_json=False, keep_packets=False, display_filter=display_filter)#, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wireshark display filters\n",
    "TSHARK_DF_AND = \"&&\"\n",
    "TSHARK_DF_OR = \"||\"\n",
    "\n",
    "# Template filter for different IPs\n",
    "TSHARK_DF_IPFILTER_fmt = \"ip.addr == {}\"\n",
    "TSHARK_DF_IPFILTER_SRC_fmt = \"ip.src_host == {}\"\n",
    "TSHARK_DF_IPFILTER_DST_fmt = \"ip.dst_host == {}\"\n",
    "TSHARK_DF_IPFILTER = lambda ip :  TSHARK_DF_IPFILTER_fmt.format(ip)\n",
    "TSHARK_DF_IPFILTER_SRC = lambda ip :  TSHARK_DF_IPFILTER_SRC_fmt.format(ip)\n",
    "TSHARK_DF_IPFILTER_DST = lambda ip :  TSHARK_DF_IPFILTER_DST_fmt.format(ip)\n",
    "\n",
    "# Filters for different MQTT packets\n",
    "MQTT_PUBLISH_MSGTYPE = 3\n",
    "MQTT_PUBACK_MSGTYPE = 4\n",
    "MQTT_PUBCOMP_MSGTYPE = 7\n",
    "\n",
    "TSHARK_DF_MQTTPUBLISH = f\"mqtt.msgtype == {MQTT_PUBLISH_MSGTYPE}\"\n",
    "TSHARK_DF_MQTTPUBACK = f\"mqtt.msgtype == {MQTT_PUBACK_MSGTYPE}\"\n",
    "TSHARK_DF_MQTTPUBCOMP = f\"mqtt.msgtype == {MQTT_PUBCOMP_MSGTYPE}\"\n",
    "\n",
    "# Filters the 1883 port so we only get MQTT packets\n",
    "TSHARK_DF_MQTT_TCPFILTER = \"tcp.port == 1883\"\n",
    "\n",
    "# Filter for ACK packets and their corresponding ACK'd frame\n",
    "TSHARK_DF_ACKS_FRAME_fmt = \"tcp.analysis.acks_frame >= {}\"\n",
    "TSHARK_DF_ACKS_FRAME = lambda number :  TSHARK_DF_ACKS_FRAME_fmt.format(number)\n",
    "\n",
    "# pyshark doesn't provide any easy way to access the data, so we need to do this to get it\n",
    "TSHARK_DF_START_ON_FRAME_fmt = \"frame.number > {}\"\n",
    "TSHARK_DF_START_ON_FRAME = lambda number :  TSHARK_DF_START_ON_FRAME_fmt.format(number)\n",
    "TSHARK_DF_GET_FRAME_fmt = \"frame.number == {}\"\n",
    "TSHARK_DF_GET_FRAME = lambda number :  TSHARK_DF_GET_FRAME_fmt.format(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log files are processed in two-passes:\n",
    "# - First pass scans for MQTT packets and gets their info (segment numbers for MQTT PUBLISH, etc)\n",
    "# - Second pass processes the underlying TCP fragments and ACKs and updates the previous info with timestamps when needed\n",
    "\n",
    "def process_logfile(frequency, number_of_clients, qos_level, packet_size):\n",
    "    capture_filename = getLogFilename(frequency, number_of_clients, qos_level, packet_size)\n",
    "    packet_info = []\n",
    "    \n",
    "    # print filename so we get some verbosity in the console\n",
    "    print(capture_filename)\n",
    "\n",
    "    # split capture according to QoS level\n",
    "    if (qos_level == 0):\n",
    "        # dict of all MQTT publish packets: map from {frame.number -> packet_data}\n",
    "        mqttpub_packet_list = {}\n",
    "\n",
    "        # create file capture to parse only MQTT packets\n",
    "        mqtt_capture = createFileCapture(capture_filename, TSHARK_DF_MQTTPUBLISH)\n",
    "\n",
    "        for packet in mqtt_capture:\n",
    "            # check for multiple MQTT layers \n",
    "            for mqtt_layer in packet.get_multiple_layers(\"mqtt\"):   \n",
    "                if (int(mqtt_layer.msgtype) == MQTT_PUBLISH_MSGTYPE):    \n",
    "                    # get packet data\n",
    "                    packet_data = {\n",
    "                        IP_ADDR_HEADER: [packet.ip.src, packet.ip.dst],\n",
    "                        FRAME_TIMESTAMP_HEADER: float(packet.frame_info.time_epoch),\n",
    "                        FRAME_NUMBER_HEADER: int(packet.frame_info.number),\n",
    "                        TCP_FIRST_SEGMENT_HEADER: int(packet.data.tcp_segment.all_fields[0].get_default_value() if (\"data\" in packet) else packet.frame_info.number),\n",
    "                        MQTT_MSGLEN_HEADER: int(packet.mqtt.len),\n",
    "                        TCP_FIRST_SEGMENT_TIMESTAMP_HEADER: float(packet.frame_info.time_epoch) if not (\"data\" in packet) else None,\n",
    "                    }\n",
    "                    mqttpub_packet_list[packet_data[TCP_FIRST_SEGMENT_HEADER]] = packet_data \n",
    "\n",
    "        # close subprocess\n",
    "        mqtt_capture.close()\n",
    "\n",
    "        # create a queue so we can ACK the packets in order (this assumes that the ACKs are not out of order)\n",
    "        # queues are created per client to validate the ACKs properly\n",
    "        mqttpub_packet_deque = {client: deque(sorted(filter(lambda packet: client == getClientIP(packet[IP_ADDR_HEADER]), mqttpub_packet_list.values()), \n",
    "            key=(lambda packet: -packet[FRAME_NUMBER_HEADER]))) for client in client_list}\n",
    "\n",
    "        # grab last packet of each client\n",
    "        last_packet_to_ack = {client: mqttpub_packet_deque[client].pop() for client in client_list if len(mqttpub_packet_deque[client]) > 0}\n",
    "\n",
    "        # check all TCP packets captured\n",
    "        tcp_capture = createFileCapture(capture_filename, TSHARK_DF_MQTT_TCPFILTER)\n",
    "        for packet in tcp_capture:\n",
    "            if packet.ip.dst == host_ip:\n",
    "                # check if it's an ACK packet from the client \n",
    "                if \"analysis_acks_frame\" in packet.tcp.field_names:\n",
    "                    # check if there's a packet that is missing an ACK\n",
    "                    if (last_packet_to_ack.get(packet.ip.src) is not None):\n",
    "                        # check if it ACKs the client's last PUBLISH\n",
    "                        if (int(packet.tcp.analysis_acks_frame) >= last_packet_to_ack.get(packet.ip.src)[FRAME_NUMBER_HEADER]):\n",
    "                            # add packet to the list\n",
    "                            packet_info.append({\n",
    "                                FREQUENCY_HEADER: frequency,\n",
    "                                MQTT_MSGLEN_HEADER: last_packet_to_ack.get(packet.ip.src)[MQTT_MSGLEN_HEADER],\n",
    "                                PACKET_SIZE_HEADER: packet_sizes_bytes[packet_size],\n",
    "                                NUM_CLIENTS_HEADER: number_of_clients,\n",
    "                                QOS_LEVEL_HEADER: qos_level,\n",
    "                                RTT_HEADER: (float(packet.frame_info.time_epoch) - mqttpub_packet_list[last_packet_to_ack.get(packet.ip.src)[TCP_FIRST_SEGMENT_HEADER]][TCP_FIRST_SEGMENT_TIMESTAMP_HEADER])\n",
    "                            })\n",
    "                            # update last packet ACK'd\n",
    "                            last_packet_to_ack[packet.ip.src] = mqttpub_packet_deque[packet.ip.src].pop() if len(mqttpub_packet_deque[packet.ip.src]) > 0 else None\n",
    "            else:\n",
    "                # check if the current packet is one of the first segments, if not then skip\n",
    "                if mqttpub_packet_list.get(int(packet.frame_info.number)) is not None:\n",
    "                    mqttpub_packet_list[int(packet.frame_info.number)][TCP_FIRST_SEGMENT_TIMESTAMP_HEADER] = float(packet.frame_info.time_epoch)\n",
    "    else:\n",
    "        # dict of all MQTT publish packets: map from {packet.ip.addr -> packet_data}\n",
    "        mqttpub_packet_list = {}\n",
    "\n",
    "        # create file capture to parse only MQTT packets\n",
    "        mqtt_capture = createFileCapture(capture_filename, \n",
    "            display_filter = ((TSHARK_DF_MQTTPUBLISH + TSHARK_DF_OR + TSHARK_DF_MQTTPUBACK) if (qos_level == 1) else \n",
    "            (TSHARK_DF_MQTTPUBLISH + TSHARK_DF_OR + TSHARK_DF_MQTTPUBCOMP)))\n",
    "        \n",
    "        for packet in mqtt_capture:\n",
    "            # check for multiple MQTT layers \n",
    "            for mqtt_layer in packet.get_multiple_layers(\"mqtt\"):  \n",
    "                # skip malformed packets / fragments\n",
    "                if (\"msgid\" in mqtt_layer.field_names):\n",
    "                    # check if it's a MQTT PUBLISH \n",
    "                    if (int(mqtt_layer.msgtype) == MQTT_PUBLISH_MSGTYPE): \n",
    "                        packet_data = {\n",
    "                            IP_ADDR_HEADER: [packet.ip.src, packet.ip.dst],\n",
    "                            FRAME_TIMESTAMP_HEADER: float(packet.frame_info.time_epoch),\n",
    "                            FRAME_NUMBER_HEADER: int(packet.frame_info.number),\n",
    "                            TCP_FIRST_SEGMENT_HEADER: int(packet.data.tcp_segment if (\"data\" in packet) else packet.frame_info.number),\n",
    "                            MQTT_MSGLEN_HEADER: int(packet.mqtt.len),\n",
    "                            TCP_FIRST_SEGMENT_TIMESTAMP_HEADER: float(packet.frame_info.time_epoch) if not (\"data\" in packet) else None,\n",
    "                            MQTT_PACKET_ACK_TIMESTAMP_HEADER: None,\n",
    "                            MQTT_PACKET_ACKED_HEADER: False,\n",
    "                        }\n",
    "                        mqttpub_packet_list[(frozenset([packet.ip.src, packet.ip.dst]), int(packet.mqtt.msgid))] = packet_data\n",
    "                    #check if it's a PUBACK / PUBCOMP (in case of random MQTT pings or other packets we're not interested in)\n",
    "                    elif(int(mqtt_layer.msgtype) == MQTT_PUBACK_MSGTYPE or int(mqtt_layer.msgtype) == MQTT_PUBCOMP_MSGTYPE):  \n",
    "                        # get saved packet\n",
    "                        mqtt_packet = mqttpub_packet_list.get((frozenset([packet.ip.src, packet.ip.dst]), int(mqtt_layer.msgid)))\n",
    "                        \n",
    "                        if mqtt_packet is not None:\n",
    "                            mqttpub_packet_list[(frozenset([packet.ip.src, packet.ip.dst]), int(mqtt_layer.msgid))][MQTT_PACKET_ACK_TIMESTAMP_HEADER] = float(packet.frame_info.time_epoch)\n",
    "                            mqttpub_packet_list[(frozenset([packet.ip.src, packet.ip.dst]), int(mqtt_layer.msgid))][MQTT_PACKET_ACKED_HEADER] = True\n",
    "        \n",
    "        # close subprocess\n",
    "        mqtt_capture.close()\n",
    "\n",
    "        # reshape dict to be indexed by first segment frame number\n",
    "        mqttpub_packet_list = {packet[TCP_FIRST_SEGMENT_HEADER]: packet for packet in mqttpub_packet_list.values() if packet[MQTT_PACKET_ACKED_HEADER]}\n",
    "\n",
    "        # check all TCP packets sent by the broker to fetch the first fragments sent per MQTT packet\n",
    "        tcp_capture = createFileCapture(capture_filename, TSHARK_DF_MQTT_TCPFILTER + TSHARK_DF_AND + TSHARK_DF_IPFILTER_SRC(host_ip))\n",
    "        for packet in tcp_capture:\n",
    "            # check if the current packet is one of the first segments, if not then skip\n",
    "            if mqttpub_packet_list.get(int(packet.frame_info.number)) is not None:\n",
    "                packet_info.append({\n",
    "                    FREQUENCY_HEADER: frequency,\n",
    "                    MQTT_MSGLEN_HEADER:  mqttpub_packet_list[int(packet.frame_info.number)][MQTT_MSGLEN_HEADER],\n",
    "                    PACKET_SIZE_HEADER: packet_sizes_bytes[packet_size],\n",
    "                    NUM_CLIENTS_HEADER: number_of_clients,\n",
    "                    QOS_LEVEL_HEADER: qos_level,\n",
    "                    RTT_HEADER:  mqttpub_packet_list[int(packet.frame_info.number)][MQTT_PACKET_ACK_TIMESTAMP_HEADER] - float(packet.frame_info.time_epoch) \n",
    "                })\n",
    "    return packet_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame(packets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list placeholder (to concat the info faster and convert it to a DataFrame in the end)\n",
    "mqttpacket_raw_info = []\n",
    "\n",
    "# loop through all logs\n",
    "for frequency in frequency_list:\n",
    "    for number_of_clients in range(1, len(client_list)+1):\n",
    "        for qos_level in qos_levels:\n",
    "            for packet_size in packet_sizes:\n",
    "                try:\n",
    "                    mqttpacket_raw_info = mqttpacket_raw_info + process_logfile(frequency, number_of_clients, qos_level, packet_size)\n",
    "                except (FileNotFoundError) as e:\n",
    "                    print(e) # report instances of failed / broken logs :)\n",
    "                except Exception as e:\n",
    "                    raise e\n",
    "\n",
    "# convert to a DataFrame for easy analysis \n",
    "mqttpacket_raw_info = pd.DataFrame(mqttpacket_raw_info)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure it's a dataframe (in case of a interrupt in the previous section)\n",
    "mqttpacket_raw_info = pd.DataFrame(mqttpacket_raw_info)\n",
    "\n",
    "# group data by dependent variables\n",
    "mqttpacket_raw_info_groups = mqttpacket_raw_info.groupby(by=[FREQUENCY_HEADER, NUM_CLIENTS_HEADER, PACKET_SIZE_HEADER, QOS_LEVEL_HEADER])\n",
    "\n",
    "# Get RTT mean and STD\n",
    "mqttpacket_info = mqttpacket_raw_info_groups.agg(\n",
    "        **{\n",
    "        RTT_MEAN_HEADER: pd.NamedAgg(column=RTT_HEADER, aggfunc=np.mean),\n",
    "        RTT_STD_HEADER: pd.NamedAgg(column=RTT_HEADER, aggfunc=np.std),\n",
    "    })\n",
    "\n",
    "# Grab nº of packets sent & reset\n",
    "mqttpacket_info[PACKET_LOSS_HEADER] = mqttpacket_raw_info_groups.size()\n",
    "mqttpacket_info.reset_index(inplace=True) \n",
    "\n",
    "# Calculate the nº of packets sent and fix the value when more than 1000 packets per client are sent\n",
    "mqttpacket_info[PACKET_LOSS_HEADER] = (1-(mqttpacket_info[PACKET_LOSS_HEADER] / (1000*mqttpacket_info[NUM_CLIENTS_HEADER])))*100\n",
    "mqttpacket_info.loc[mqttpacket_info[PACKET_LOSS_HEADER] < 0, [PACKET_LOSS_HEADER,]] = 0 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame(process_packet(10, 3, 2, \"large\")))\n",
    "print(pd.DataFrame(process_packet(10, 4, 2, \"large\")))\n",
    "print(pd.DataFrame(process_packet(100, 1, 2, \"large\")))\n",
    "print(pd.DataFrame(process_packet(100, 1, 2, \"large\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame(process_packet(100, 3, 2, \"small\")))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
