{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "'''MQTT Packet analysis script developed for the experiments ran in ISR.\n",
    "\n",
    "This script automatically performs the RTT and Packet Loss analysis of the packets given the folder containing\n",
    "all Wireshark capture files ('.pcap'). \n",
    "\n",
    "It uses pyshark (Python wrapper for the tshark tool) to analyze the packets.\n",
    "\n",
    "Setting up:\n",
    "    Use the supplied Dockerfile to setup a development environment, or manually install all dependencies.\n",
    "    Make sure to mount the folder with the log files in /logs/.\n",
    "'''\n",
    "\n",
    "import pyshark\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "\n",
    "# fix nested loop shenanigans with Jupyter\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all experiment variables\n",
    "client_list =  ['10.231.219.206', '10.231.219.81', '10.231.219.73', '10.231.219.185']\n",
    "host_ip = '10.231.201.175'\n",
    "\n",
    "frequency_list =  [1, 10, 100]\n",
    "packet_sizes =  ['small', 'medium', 'large']\n",
    "qos_levels = [0, 1, 2]\n",
    "\n",
    "# Mapping to get real packet size\n",
    "packet_sizes_bytes = {'small': 1250, 'medium': 12500, 'large': 125000}\n",
    "\n",
    "# Headers to be used in pandas.DataFrame\n",
    "FREQUENCY_HEADER = 'FREQUENCY'\n",
    "PACKET_SIZE_HEADER = 'PACKET_SIZE'\n",
    "NUM_CLIENTS_HEADER = 'NUM_CLIENTS'\n",
    "QOS_LEVEL_HEADER = 'QOS_LEVEL'\n",
    "\n",
    "RTT_HEADER = 'RTT'\n",
    "RTT_MEAN_HEADER = 'RTT_MEAN' \n",
    "RTT_STD_HEADER = 'RTT_STD'\n",
    "PACKET_LOSS_HEADER = 'PACKET_LOSS'\n",
    "\n",
    "# Headers to be used in packet_raw_info\n",
    "TCP_SEGMENTS_HEADER = \"tcp.segments\" # segments that composed the packet\n",
    "TCP_FIRST_SEGMENT_HEADER = TCP_SEGMENTS_HEADER # first segment that composed the packet \n",
    "TCP_FIRST_SEGMENT_TIMESTAMP_HEADER = \"tcp.segments.timestamp\" # first segment that composed the packet \n",
    "\n",
    "MQTT_MSGID_HEADER = \"mqtt.msgid\" # id of the MQTT message, used to follow up on QoS on MQTT level\n",
    "MQTT_MSGLEN_HEADER = \"mqtt.msglen\" # full length of the packet (payload + overhead)\n",
    "FRAME_NUMBER_HEADER = \"frame.number\" # number of the frame\n",
    "FRAME_TIMESTAMP_HEADER = \"frame.time\" # timestamp of the recorded packet\n",
    "IP_ADDR_HEADER = \"ip.addr\"\n",
    "\n",
    "MQTT_PACKET_ACKED_HEADER = \"MQTT_PACKET_ACKED\" # indicates if the packed was acked or not\n",
    "MQTT_PACKET_ACK_TIMESTAMP_HEADER = \"MQTT_PACKET_ACK_TIMESTAMP\" # timestamp of packet ack (PUBACK for QoS1, PUBCOMP for QoS2)\n",
    "\n",
    "# Useful functions\n",
    "# Packet file name format\n",
    "filename_fmt = '/logs/f{}c{}qos{}{}.pcap'\n",
    "getLogFilename = lambda frequency, number_of_clients, qos_level, packet_size : filename_fmt.format(frequency, number_of_clients, qos_level, packet_size)\n",
    "\n",
    "# Get Client IP from ip.addr info\n",
    "getClientIP = lambda addr: addr[0] if addr[0] != host_ip else addr[1] \n",
    "\n",
    "# Create FileCapture from capture file and display filter \n",
    "createFileCapture = lambda capture_filename, display_filter: pyshark.FileCapture(capture_filename, use_json=True, keep_packets=False, display_filter=display_filter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wireshark display filters\n",
    "TSHARK_DF_AND = \"&&\"\n",
    "TSHARK_DF_OR = \"||\"\n",
    "\n",
    "# Template filter for different IPs\n",
    "TSHARK_DF_IPFILTER_fmt = \"ip.addr == {}\"\n",
    "TSHARK_DF_IPFILTER = lambda ip :  TSHARK_DF_IPFILTER_fmt.format(ip)\n",
    "\n",
    "# Filters for different MQTT packets\n",
    "MQTT_PUBLISH_MSGTYPE = 3\n",
    "MQTT_PUBACK_MSGTYPE = 5\n",
    "MQTT_PUBCOMP_MSGTYPE = 7\n",
    "\n",
    "TSHARK_DF_MQTTPUBLISH = f\"mqtt.msgtype == {MQTT_PUBLISH_MSGTYPE}\"\n",
    "TSHARK_DF_MQTTPUBACK = f\"mqtt.msgtype == {MQTT_PUBACK_MSGTYPE}\"\n",
    "TSHARK_DF_MQTTPUBCOMP = f\"mqtt.msgtype == {MQTT_PUBCOMP_MSGTYPE}\"\n",
    "\n",
    "# filters the 1883 port so we only get MQTT packets\n",
    "TSHARK_DF_MQTT_TCPFILTER = \"tcp.port == 1883\"\n",
    "TSHARK_DF_MQTT_IGNORE_PINGS= \"!(mqtt.msgtype == 12)\"\n",
    "\n",
    "# Filter for ACK packets and their corresponding ACK'd frame\n",
    "TSHARK_DF_ACKS_FRAME_fmt = \"tcp.analysis.acks_frame >= {}\"\n",
    "TSHARK_DF_ACKS_FRAME = lambda number :  TSHARK_DF_ACKS_FRAME_fmt.format(number)\n",
    "\n",
    "# pyshark doesn't provide any easy way to access the data, so we need to do this to get it\n",
    "TSHARK_DF_START_ON_FRAME_fmt = \"frame.number > {}\"\n",
    "TSHARK_DF_START_ON_FRAME = lambda number :  TSHARK_DF_START_ON_FRAME_fmt.format(number)\n",
    "TSHARK_DF_GET_FRAME_fmt = \"frame.number == {}\"\n",
    "TSHARK_DF_GET_FRAME = lambda number :  TSHARK_DF_GET_FRAME_fmt.format(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log files are processed in two-passes:\n",
    "# - First pass scans for MQTT packets and gets their info (segment numbers for MQTT PUBLISH, etc)\n",
    "# - Second pass processes the underlying TCP fragments and ACKs and updates the previous info with timestamps when needed\n",
    "\n",
    "def process_packet(frequency, number_of_clients, qos_level, packet_size):\n",
    "    capture_filename = getLogFilename(frequency, number_of_clients, qos_level, packet_size)\n",
    "    packet_info = []\n",
    "    \n",
    "    # split capture according to QoS level\n",
    "    if (qos_level == 0):\n",
    "        # dict of all MQTT publish packets: map from {frame.number -> packet_data}\n",
    "        mqttpub_packet_list = {}\n",
    "\n",
    "        # needs json to capture segment data\n",
    "        mqtt_capture = createFileCapture(capture_filename, TSHARK_DF_MQTTPUBLISH + TSHARK_DF_AND + TSHARK_DF_MQTT_IGNORE_PINGS)\n",
    "        for packet in mqtt_capture:\n",
    "            # get packet data\n",
    "            packet_data = {\n",
    "                IP_ADDR_HEADER: packet.ip.addr,\n",
    "                FRAME_TIMESTAMP_HEADER: float(packet.frame_info.time_epoch),\n",
    "                FRAME_NUMBER_HEADER: int(packet.frame_info.number),\n",
    "                TCP_FIRST_SEGMENT_HEADER: int(packet[TCP_SEGMENTS_HEADER].segment[0] if packet.__contains__(TCP_SEGMENTS_HEADER) else packet.frame_info.number),\n",
    "                MQTT_MSGLEN_HEADER: int(packet.mqtt.len),\n",
    "                TCP_FIRST_SEGMENT_TIMESTAMP_HEADER: float(packet.frame_info.time_epoch) if not packet.__contains__(TCP_SEGMENTS_HEADER) else None\n",
    "            }\n",
    "            mqttpub_packet_list[packet_data[TCP_FIRST_SEGMENT_HEADER]] = packet_data \n",
    "\n",
    "        # close subprocess\n",
    "        mqtt_capture.close()\n",
    "\n",
    "        # create a queue so we can ACK the packets in order (this assumes that the ACKs are not out of order)\n",
    "        # queues are created per client to validate the ACKs properly\n",
    "        mqttpub_packet_deque = {client: deque(sorted(filter(lambda packet: client == getClientIP(packet[IP_ADDR_HEADER]), mqttpub_packet_list.values()), \n",
    "            key=(lambda packet: -packet[FRAME_NUMBER_HEADER]))) for client in client_list}\n",
    "\n",
    "        # grab last packet of each client\n",
    "        last_packet_to_ack = {client: mqttpub_packet_deque[client].pop() for client in client_list if len(mqttpub_packet_deque[client]) > 0}\n",
    "\n",
    "        tcp_capture = createFileCapture(capture_filename, TSHARK_DF_MQTT_TCPFILTER)\n",
    "        for packet in tcp_capture:\n",
    "            # check if it's an ACK packet\n",
    "            if packet.ip.dst == host_ip: \n",
    "                if packet.tcp.has_field(\"analysis\") and packet.tcp.analysis.has_field(\"acks_frame\"):\n",
    "                    if (last_packet_to_ack.get(packet.ip.src) is not None):\n",
    "                        # check if it ACKs the client's last PUBLISH\n",
    "                        if (packet.tcp.analysis.acks_frame.main_field.int_value >= last_packet_to_ack.get(packet.ip.src)[FRAME_NUMBER_HEADER]):\n",
    "                            # add packet to the list\n",
    "                            packet_info.append({\n",
    "                                FREQUENCY_HEADER: frequency,\n",
    "                                MQTT_MSGLEN_HEADER: packet_data[MQTT_MSGLEN_HEADER],\n",
    "                                PACKET_SIZE_HEADER: packet_sizes_bytes[packet_size],\n",
    "                                NUM_CLIENTS_HEADER: number_of_clients,\n",
    "                                QOS_LEVEL_HEADER: qos_level,\n",
    "                                RTT_HEADER: (float(packet.frame_info.time_epoch) - mqttpub_packet_list[last_packet_to_ack.get(packet.ip.src)[TCP_FIRST_SEGMENT_HEADER]][TCP_FIRST_SEGMENT_TIMESTAMP_HEADER])\n",
    "                            })\n",
    "                            # update last packet ACK'd\n",
    "                            last_packet_to_ack[packet.ip.src] = mqttpub_packet_deque[packet.ip.src].pop() if len(mqttpub_packet_deque[packet.ip.src]) > 0 else None\n",
    "            else:\n",
    "                # check if the current packet is one of the first segments, if not then skip\n",
    "                if mqttpub_packet_list.get(int(packet.frame_info.number)) is not None:\n",
    "                    mqttpub_packet_list[int(packet.frame_info.number)][TCP_FIRST_SEGMENT_TIMESTAMP_HEADER] = float(packet.frame_info.time_epoch)\n",
    "    else:\n",
    "        # dict of all MQTT publish packets: map from {packet.ip.addr -> packet_data}\n",
    "        mqttpub_packet_list = {}\n",
    "\n",
    "        # needs json to capture segment data\n",
    "        mqtt_capture = createFileCapture(capture_filename, \n",
    "            display_filter = ((TSHARK_DF_MQTTPUBLISH + TSHARK_DF_OR + TSHARK_DF_MQTTPUBACK) if (qos_level == 1) else \n",
    "            (TSHARK_DF_MQTTPUBLISH + TSHARK_DF_OR + TSHARK_DF_MQTTPUBCOMP)))\n",
    "        \n",
    "        for packet in mqtt_capture:\n",
    "            # check if it's a MQTT PUBLISH \n",
    "            if (int(packet.mqtt.hdrflags_tree.msgtype) == MQTT_PUBLISH_MSGTYPE): \n",
    "                packet_data = {\n",
    "                    IP_ADDR_HEADER: packet.ip.addr,\n",
    "                    FRAME_TIMESTAMP_HEADER: float(packet.frame_info.time_epoch),\n",
    "                    FRAME_NUMBER_HEADER: int(packet.frame_info.number),\n",
    "                    TCP_FIRST_SEGMENT_HEADER: int(packet[TCP_SEGMENTS_HEADER].segment[0] if packet.__contains__(TCP_SEGMENTS_HEADER) else packet.frame_info.number),\n",
    "                    MQTT_MSGLEN_HEADER: int(packet.mqtt.len),\n",
    "                    TCP_FIRST_SEGMENT_TIMESTAMP_HEADER: float(packet.frame_info.time_epoch) if not packet.__contains__(TCP_SEGMENTS_HEADER) else None,\n",
    "                    MQTT_PACKET_ACK_TIMESTAMP_HEADER: None,\n",
    "                    MQTT_PACKET_ACKED_HEADER: False,\n",
    "                }\n",
    "                mqttpub_packet_list[(frozenset(packet.ip.addr), packet.mqtt.msgid)] = packet_data\n",
    "\n",
    "            else: # then it's a PUBACK / PUBCOMP\n",
    "                # get saved packet\n",
    "                mqtt_packet = mqttpub_packet_list.get((frozenset(packet.ip.addr), packet.mqtt.msgid))\n",
    "                if mqtt_packet is not None:\n",
    "                    mqttpub_packet_list[(frozenset(packet.ip.addr), packet.mqtt.msgid)][MQTT_PACKET_ACK_TIMESTAMP_HEADER] = float(packet.frame_info.time_epoch)\n",
    "                    mqttpub_packet_list[(frozenset(packet.ip.addr), packet.mqtt.msgid)][MQTT_PACKET_ACKED_HEADER] = True    \n",
    "        \n",
    "        # reshape dict to be indexed by first segment frame number\n",
    "        mqttpub_packet_list = {packet[TCP_FIRST_SEGMENT_HEADER]: packet for packet in mqttpub_packet_list.values()}\n",
    "        \n",
    "        # close subprocess\n",
    "        mqtt_capture.close()\n",
    "\n",
    "        # create a queue so we can ACK the packets in order (this assumes that the ACKs are not out of order)\n",
    "        # queues are created per client to validate the ACKs properly\n",
    "        mqttpub_packet_deque = {client: deque(sorted(filter(lambda packet: client == getClientIP(packet[IP_ADDR_HEADER]), mqttpub_packet_list.values()), \n",
    "            key=(lambda packet: -packet[FRAME_NUMBER_HEADER]))) for client in client_list}\n",
    "\n",
    "        # grab last packet of each client\n",
    "        last_packet_to_ack = {client: mqttpub_packet_deque[client].pop() for client in client_list if len(mqttpub_packet_deque[client]) > 0}\n",
    "\n",
    "        tcp_capture = createFileCapture(capture_filename, TSHARK_DF_MQTT_TCPFILTER)\n",
    "        for packet in tcp_capture:\n",
    "            # check if it's an ACK packet\n",
    "            if packet.ip.dst == host_ip: \n",
    "                if packet.tcp.has_field(\"analysis\") and packet.tcp.analysis.has_field(\"acks_frame\"):\n",
    "                    if (last_packet_to_ack.get(packet.ip.src) is not None):\n",
    "                        # check if it ACKs the client's last PUBLISH\n",
    "                        if (packet.tcp.analysis.acks_frame.main_field.int_value >= last_packet_to_ack.get(packet.ip.src)[FRAME_NUMBER_HEADER]):\n",
    "                            # add packet to the list\n",
    "                            packet_info.append({\n",
    "                                FREQUENCY_HEADER: frequency,\n",
    "                                MQTT_MSGLEN_HEADER: packet_data[MQTT_MSGLEN_HEADER],\n",
    "                                PACKET_SIZE_HEADER: packet_sizes_bytes[packet_size],\n",
    "                                NUM_CLIENTS_HEADER: number_of_clients,\n",
    "                                QOS_LEVEL_HEADER: qos_level,\n",
    "                                RTT_HEADER: (float(packet.frame_info.time_epoch) - mqttpub_packet_list[last_packet_to_ack.get(packet.ip.src)[TCP_FIRST_SEGMENT_HEADER]][TCP_FIRST_SEGMENT_TIMESTAMP_HEADER])\n",
    "                            })\n",
    "                            # update last packet ACK'd\n",
    "                            last_packet_to_ack[packet.ip.src] = mqttpub_packet_deque[packet.ip.src].pop() if len(mqttpub_packet_deque[packet.ip.src]) > 0 else None\n",
    "            else:\n",
    "                # check if the current packet is one of the first segments, if not then skip\n",
    "                if mqttpub_packet_list.get(int(packet.frame_info.number)) is not None:\n",
    "                    mqttpub_packet_list[int(packet.frame_info.number)][TCP_FIRST_SEGMENT_TIMESTAMP_HEADER] = float(packet.frame_info.time_epoch)\n",
    "    return packet_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyzed info\n",
    "mqttpacket_info = pd.DataFrame(None, columns=[NUM_CLIENTS_HEADER, QOS_LEVEL_HEADER, FREQUENCY_HEADER, PACKET_SIZE_HEADER, RTT_MEAN_HEADER, RTT_STD_HEADER, PACKET_LOSS_HEADER])\n",
    "mqttpacket_raw_info = []\n",
    "\n",
    "# loop through all logs\n",
    "for frequency in frequency_list:\n",
    "    for number_of_clients in range(1, len(client_list)+1):\n",
    "        for qos_level in qos_levels:\n",
    "            for packet_size in packet_sizes:\n",
    "                print((frequency, number_of_clients, qos_level, packet_size))\n",
    "                try:\n",
    "                    mqttpacket_raw_info = mqttpacket_raw_info + process_packet(frequency, number_of_clients, qos_level, packet_size)\n",
    "                except (FileNotFoundError, pyshark.TSharkCrashException) as e:\n",
    "                    print(e) # report instances of failed / broken logs :)\n",
    "                except Exception as e:\n",
    "                    raise e\n",
    "\n",
    "# convert to a DataFrame for easy analysis \n",
    "mqttpacket_raw_info = pd.DataFrame(mqttpacket_raw_info)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "mqttpacket_raw_info = pd.DataFrame(mqttpacket_raw_info)\n",
    "\n",
    "# group data by dependent variables\n",
    "mqttpacket_raw_info_groups = mqttpacket_raw_info.groupby(by=[FREQUENCY_HEADER, NUM_CLIENTS_HEADER, PACKET_SIZE_HEADER, QOS_LEVEL_HEADER])\n",
    "\n",
    "# get mean & std values\n",
    "print(mqttpacket_raw_info_groups.mean())\n",
    "print(mqttpacket_raw_info_groups.std())\n",
    "\n",
    "# to estimate packet loss, count the amount of observed packets and divide it by the expected amount (1000*\"nÂº of clients\")\n",
    "print(mqttpacket_raw_info_groups.size())\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
